{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /private/var/folders/9c/jws73d7n2ksby8dj7d0vjq240000gn/T/pip-req-build-wy7j7p68\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /private/var/folders/9c/jws73d7n2ksby8dj7d0vjq240000gn/T/pip-req-build-wy7j7p68\n",
      "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting yt-dlp\n",
      "  Downloading yt_dlp-2025.3.31-py3-none-any.whl.metadata (172 kB)\n",
      "Collecting pydub\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pyannote.audio\n",
      "  Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting torch>=2.1\n",
      "  Downloading torch-2.6.0-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.6.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting more-itertools (from openai-whisper==20240930)\n",
      "  Downloading more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting numba (from openai-whisper==20240930)\n",
      "  Downloading numba-0.61.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.8 kB)\n",
      "Collecting numpy (from openai-whisper==20240930)\n",
      "  Downloading numpy-2.2.5-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting tiktoken (from openai-whisper==20240930)\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting asteroid-filterbanks>=0.4 (from pyannote.audio)\n",
      "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting einops>=0.6.0 (from pyannote.audio)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting huggingface-hub>=0.13.0 (from pyannote.audio)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting lightning>=2.0.1 (from pyannote.audio)\n",
      "  Downloading lightning-2.5.1-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting omegaconf<3.0,>=2.1 (from pyannote.audio)\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pyannote.core>=5.0.0 (from pyannote.audio)\n",
      "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyannote.database>=5.0.1 (from pyannote.audio)\n",
      "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyannote.metrics>=3.2 (from pyannote.audio)\n",
      "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pyannote.pipeline>=3.0.1 (from pyannote.audio)\n",
      "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
      "Collecting pytorch-metric-learning>=2.1.0 (from pyannote.audio)\n",
      "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting rich>=12.0.0 (from pyannote.audio)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting semver>=3.0.0 (from pyannote.audio)\n",
      "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting soundfile>=0.12.1 (from pyannote.audio)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Collecting speechbrain>=1.0.0 (from pyannote.audio)\n",
      "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tensorboardX>=2.6 (from pyannote.audio)\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting torch-audiomentations>=0.11.0 (from pyannote.audio)\n",
      "  Downloading torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting torchmetrics>=0.11.0 (from pyannote.audio)\n",
      "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting filelock (from torch>=2.1)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/adityasrivastava/miniconda3/envs/dev_endsem/lib/python3.12/site-packages (from torch>=2.1) (4.13.2)\n",
      "Collecting networkx (from torch>=2.1)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=2.1)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch>=2.1)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in /Users/adityasrivastava/miniconda3/envs/dev_endsem/lib/python3.12/site-packages (from torch>=2.1) (75.8.0)\n",
      "Collecting sympy==1.13.1 (from torch>=2.1)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=2.1)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/adityasrivastava/miniconda3/envs/dev_endsem/lib/python3.12/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (25.0)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub>=0.13.0->pyannote.audio)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting requests (from huggingface-hub>=0.13.0->pyannote.audio)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting packaging>=20.9 (from huggingface-hub>=0.13.0->pyannote.audio)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3.0,>=2.1->pyannote.audio)\n",
      "  Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sortedcontainers>=2.0.4 (from pyannote.core>=5.0.0->pyannote.audio)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting scipy>=1.1 (from pyannote.core>=5.0.0->pyannote.audio)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting pandas>=0.19 (from pyannote.database>=5.0.1->pyannote.audio)\n",
      "  Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting typer>=0.12.1 (from pyannote.database>=5.0.1->pyannote.audio)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting scikit-learn>=0.17.1 (from pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tabulate>=0.7.7 (from pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting matplotlib>=2.0.0 (from pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Downloading matplotlib-3.10.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=12.0.0->pyannote.audio)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/adityasrivastava/miniconda3/envs/dev_endsem/lib/python3.12/site-packages (from rich>=12.0.0->pyannote.audio) (2.19.1)\n",
      "Collecting cffi>=1.0 (from soundfile>=0.12.1->pyannote.audio)\n",
      "  Downloading cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting joblib (from speechbrain>=1.0.0->pyannote.audio)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting sentencepiece (from speechbrain>=1.0.0->pyannote.audio)\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting protobuf>=3.20 (from tensorboardX>=2.6->pyannote.audio)\n",
      "  Downloading protobuf-6.30.2-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.1)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba->openai-whisper==20240930)\n",
      "  Downloading llvmlite-0.44.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->openai-whisper==20240930)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Downloading fonttools-4.57.0-cp312-cp312-macosx_10_13_universal2.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Collecting pillow>=8 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Downloading pillow-11.2.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/adityasrivastava/miniconda3/envs/dev_endsem/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.9.0.post0)\n",
      "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading sqlalchemy-2.0.40-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub>=0.13.0->pyannote.audio)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->huggingface-hub>=0.13.0->pyannote.audio)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub>=0.13.0->pyannote.audio)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->huggingface-hub>=0.13.0->pyannote.audio)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting click>=8.0.0 (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading frozenlist-1.6.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading multidict-6.4.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading propcache-0.3.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading yarl-1.20.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (72 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/adityasrivastava/miniconda3/envs/dev_endsem/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.17.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp312-cp312-macosx_14_0_arm64.whl.metadata (1.2 kB)\n",
      "Downloading yt_dlp-2025.3.31-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl (898 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp312-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading torchaudio-2.6.0-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Downloading lightning-2.5.1-py3-none-any.whl (818 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
      "Downloading numpy-2.2.5-cp312-cp312-macosx_14_0_arm64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
      "Downloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
      "Downloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Downloading torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)\n",
      "Downloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Downloading numba-0.61.2-cp312-cp312-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp312-cp312-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl (178 kB)\n",
      "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading llvmlite-0.44.0-cp312-cp312-macosx_11_0_arm64.whl (26.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.2/26.2 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading matplotlib-3.10.1-cp312-cp312-macosx_11_0_arm64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl (11.4 MB)\n",
      "Downloading protobuf-6.30.2-cp39-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp312-cp312-macosx_14_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading pytorch_lightning-2.5.1-py3-none-any.whl (822 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl (1.2 MB)\n",
      "Downloading aiohttp-3.11.18-cp312-cp312-macosx_11_0_arm64.whl (457 kB)\n",
      "Downloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl (196 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading contourpy-1.3.2-cp312-cp312-macosx_11_0_arm64.whl (255 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp312-cp312-macosx_10_13_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading pillow-11.2.1-cp312-cp312-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.6.0-cp312-cp312-macosx_11_0_arm64.whl (121 kB)\n",
      "Downloading multidict-6.4.3-cp312-cp312-macosx_11_0_arm64.whl (37 kB)\n",
      "Downloading propcache-0.3.1-cp312-cp312-macosx_11_0_arm64.whl (46 kB)\n",
      "Downloading ruamel.yaml.clib-0.2.12-cp312-cp312-macosx_14_0_arm64.whl (133 kB)\n",
      "Downloading yarl-1.20.0-cp312-cp312-macosx_11_0_arm64.whl (95 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: openai-whisper, antlr4-python3-runtime, docopt, julius\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803708 sha256=a746121bec221d163105b6ace3ca1209acb3e32d25d75e688697350d2c3e6a42\n",
      "  Stored in directory: /private/var/folders/9c/jws73d7n2ksby8dj7d0vjq240000gn/T/pip-ephem-wheel-cache-utsem1eo/wheels/c3/03/25/5e0ba78bc27a3a089f137c9f1d92fdfce16d06996c071a016c\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=8a5e1251063fc10d28b9e70a38cd3036dd4d2146912ce5ecba8711ee43a10a8a\n",
      "  Stored in directory: /Users/adityasrivastava/Library/Caches/pip/wheels/1f/be/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13749 sha256=13e2ca09d4657ed93604502558034e0050ffe45ae446ae1e526ca77a4a55a200\n",
      "  Stored in directory: /Users/adityasrivastava/Library/Caches/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "  Building wheel for julius (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21933 sha256=56e3ddee617c452833f09a54b0a93c10346fe0697258a019a7aec63690b24d57\n",
      "  Stored in directory: /Users/adityasrivastava/Library/Caches/pip/wheels/de/c1/ca/544dafe48401e8e2e17064dfe465a390fca9e8720ffa12e744\n",
      "Successfully built openai-whisper antlr4-python3-runtime docopt julius\n",
      "Installing collected packages: sortedcontainers, sentencepiece, pytz, pydub, primePy, mpmath, docopt, antlr4-python3-runtime, yt-dlp, urllib3, tzdata, tqdm, threadpoolctl, tabulate, sympy, sqlalchemy, shellingham, semver, ruamel.yaml.clib, regex, pyyaml, pyparsing, pycparser, protobuf, propcache, pillow, packaging, numpy, networkx, multidict, more-itertools, mdurl, MarkupSafe, llvmlite, kiwisolver, joblib, idna, fsspec, frozenlist, fonttools, filelock, einops, cycler, colorlog, click, charset-normalizer, certifi, attrs, aiohappyeyeballs, yarl, tensorboardX, scipy, ruamel.yaml, requests, pandas, omegaconf, numba, markdown-it-py, Mako, lightning-utilities, jinja2, contourpy, cffi, aiosignal, torch, tiktoken, soundfile, scikit-learn, rich, pyannote.core, matplotlib, hyperpyyaml, huggingface-hub, alembic, aiohttp, typer, torchmetrics, torchaudio, pytorch-metric-learning, optuna, openai-whisper, julius, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.database, torch-audiomentations, pyannote.pipeline, pyannote.metrics, lightning, pyannote.audio\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed Mako-1.3.10 MarkupSafe-3.0.2 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 alembic-1.15.2 antlr4-python3-runtime-4.9.3 asteroid-filterbanks-0.4.0 attrs-25.3.0 certifi-2025.1.31 cffi-1.17.1 charset-normalizer-3.4.1 click-8.1.8 colorlog-6.9.0 contourpy-1.3.2 cycler-0.12.1 docopt-0.6.2 einops-0.8.1 filelock-3.18.0 fonttools-4.57.0 frozenlist-1.6.0 fsspec-2025.3.2 huggingface-hub-0.30.2 hyperpyyaml-1.2.2 idna-3.10 jinja2-3.1.6 joblib-1.4.2 julius-0.2.7 kiwisolver-1.4.8 lightning-2.5.1 lightning-utilities-0.14.3 llvmlite-0.44.0 markdown-it-py-3.0.0 matplotlib-3.10.1 mdurl-0.1.2 more-itertools-10.7.0 mpmath-1.3.0 multidict-6.4.3 networkx-3.4.2 numba-0.61.2 numpy-2.2.5 omegaconf-2.3.0 openai-whisper-20240930 optuna-4.3.0 packaging-24.2 pandas-2.2.3 pillow-11.2.1 primePy-1.3 propcache-0.3.1 protobuf-6.30.2 pyannote.audio-3.3.2 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pycparser-2.22 pydub-0.25.1 pyparsing-3.2.3 pytorch-lightning-2.5.1 pytorch-metric-learning-2.8.1 pytz-2025.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 rich-14.0.0 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 scikit-learn-1.6.1 scipy-1.15.2 semver-3.0.4 sentencepiece-0.2.0 shellingham-1.5.4 sortedcontainers-2.4.0 soundfile-0.13.1 speechbrain-1.0.3 sqlalchemy-2.0.40 sympy-1.13.1 tabulate-0.9.0 tensorboardX-2.6.2.2 threadpoolctl-3.6.0 tiktoken-0.9.0 torch-2.6.0 torch-audiomentations-0.12.0 torch-pitch-shift-1.2.5 torchaudio-2.6.0 torchmetrics-1.7.1 tqdm-4.67.1 typer-0.15.2 tzdata-2025.2 urllib3-2.4.0 yarl-1.20.0 yt-dlp-2025.3.31\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Install dependencies (run once)\n",
    "%pip install --upgrade \"git+https://github.com/openai/whisper.git\" \\\n",
    "                        yt-dlp pydub tqdm pyannote.audio \"torch>=2.1\" torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code] Imports & paths\n",
    "import os, re, json, math, tempfile, uuid\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import yt_dlp\n",
    "from pydub import AudioSegment\n",
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code] Config\n",
    "YOUTUBE_URL = \"https://www.youtube.com/watch?v=SJKr7BPOXY0\"  # 👈 paste podcast link\n",
    "\n",
    "WHISPER_MODEL_NAME = \"base.en\"      # or \"medium\", \"large-v3\", etc.\n",
    "CHUNK_MINUTES      = 1        \n",
    "DOWNLOAD_MINUTES    = 2              # 👈 only download first N minutes     # Whisper handles ~30‑min, but 10 keeps GPU memory low\n",
    "NUM_THREADS        = 4              # parallel chunk transcription\n",
    "HF_TOKEN           = \"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\"  # speaker diarization\n",
    "OUTPUT_DIR         = Path(\"outputs\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded → outputs/91c71ed3-5cef-4e54-a20b-ce9e5a9cc490.wav\n",
      "Trimmed to 2 min → outputs/91c71ed3-5cef-4e54-a20b-ce9e5a9cc490_first2m.wav\n"
     ]
    }
   ],
   "source": [
    "# %% [code] 1️⃣  Download YouTube audio\n",
    "def download_audio(url: str) -> Path:\n",
    "    \"\"\"Download highest‑quality audio, return local .wav path.\"\"\"\n",
    "    out = OUTPUT_DIR / f\"{uuid.uuid4()}.%(ext)s\"\n",
    "    ydl_opts = {\n",
    "        \"format\": \"bestaudio/best\",\n",
    "        \"outtmpl\": str(out),\n",
    "        \"postprocessors\": [\n",
    "            {\"key\": \"FFmpegExtractAudio\", \"preferredcodec\": \"wav\", \"preferredquality\": \"192\"}\n",
    "        ],\n",
    "        \"quiet\": True,\n",
    "        \"no_warnings\": True,\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "    return next(OUTPUT_DIR.glob(out.name.replace(\"%(ext)s\", \"wav\")))\n",
    "\n",
    "wav_path = download_audio(YOUTUBE_URL)\n",
    "print(\"Downloaded →\", wav_path)\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "if DOWNLOAD_MINUTES:\n",
    "    orig = AudioSegment.from_file(wav_path)\n",
    "    trimmed = orig[: DOWNLOAD_MINUTES * 60_000 ]\n",
    "    trimmed_path = wav_path.with_name(wav_path.stem + f\"_first{DOWNLOAD_MINUTES}m.wav\")\n",
    "    trimmed.export(trimmed_path, format=\"wav\")\n",
    "    wav_path = trimmed_path\n",
    "    print(f\"Trimmed to {DOWNLOAD_MINUTES} min →\", wav_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(chunks)=2\n"
     ]
    }
   ],
   "source": [
    "# %% [code] 2️⃣  Chunk helper\n",
    "def chunk_audio(wav_file: Path, minutes: int = CHUNK_MINUTES):\n",
    "    audio = AudioSegment.from_file(wav_file)\n",
    "    ms = minutes * 60_000\n",
    "    chunks = []\n",
    "    for i in range(0, len(audio), ms):\n",
    "        chunk = audio[i : i + ms]\n",
    "        chunk_path = wav_file.with_suffix(f\".part{i//ms}.wav\")\n",
    "        chunk.export(chunk_path, format=\"wav\")\n",
    "        chunks.append((i / 1000.0, chunk_path))      # (chunk_offset_seconds, path)\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_audio(wav_path) if CHUNK_MINUTES else [(0, wav_path)]\n",
    "print(f\"{len(chunks)=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code] 3️⃣  Load Whisper\n",
    "device =  \"cpu\"\n",
    "whisper_model = whisper.load_model(WHISPER_MODEL_NAME, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [00:03<00:00, 1633.49frames/s]\n",
      "100%|██████████| 6000/6000 [00:03<00:00, 1749.99frames/s]\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total segments: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %% [code] 4️⃣  Transcribe chunks in parallel\n",
    "# %% [code] 3.1️⃣  Thread‐safety for Whisper\n",
    "import threading\n",
    "model_lock = threading.Lock()\n",
    "\n",
    "# %% [code] 4️⃣  Transcribe chunks in parallel (thread‐safe)\n",
    "def transcribe_one(offset_sec, path):\n",
    "    # we only allow one thread at a time into whisper_model.transcribe\n",
    "    with model_lock:\n",
    "        result = whisper_model.transcribe(\n",
    "            str(path),\n",
    "            word_timestamps=True,\n",
    "            verbose=False,\n",
    "            fp16=device==\"cuda\",\n",
    "            initial_prompt=None\n",
    "        )\n",
    "    # shift timestamps by chunk offset so they are global\n",
    "    for seg in result[\"segments\"]:\n",
    "        seg[\"start\"] += offset_sec\n",
    "        seg[\"end\"]   += offset_sec\n",
    "        for wd in seg[\"words\"]:\n",
    "            wd[\"start\"] += offset_sec\n",
    "            wd[\"end\"]   += offset_sec\n",
    "    return result[\"segments\"]\n",
    "\n",
    "all_segments = []\n",
    "with ThreadPoolExecutor(max_workers=NUM_THREADS) as ex:\n",
    "    futures = [ex.submit(transcribe_one, off, p) for off, p in chunks]\n",
    "    for f in tqdm(as_completed(futures), total=len(futures)):\n",
    "        all_segments.extend(f.result())\n",
    "\n",
    "all_segments.sort(key=lambda s: s[\"start\"])\n",
    "print(f\"Total segments: {len(all_segments)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityasrivastava/miniconda3/envs/dev_endsem/lib/python3.12/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    }
   ],
   "source": [
    "# %% [code] 5️⃣  Run PyAnnote diarization\n",
    "assert HF_TOKEN, \"Set HF_TOKEN env variable first!\"\n",
    "dia_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\",\n",
    "                                         use_auth_token=HF_TOKEN,\n",
    "                                         cache_dir=str(Path.home()/\".cache/pyannote\"))\n",
    "dia_result = dia_pipeline(str(wav_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged into 3 speaker turns\n"
     ]
    }
   ],
   "source": [
    "# %% [code] 5.1️⃣  Robust assign_speakers\n",
    "from itertools import groupby\n",
    "\n",
    "def assign_speakers(segments, diarization):\n",
    "    \"\"\"\n",
    "    Merge Whisper word‑level output with PyAnnote diarization.\n",
    "    Returns a list of dicts: {speaker, start, end, text}\n",
    "    \"\"\"\n",
    "    # ---- 1. Flatten diarization ----\n",
    "    time_speakers = []\n",
    "    for item in diarization.itertracks(yield_label=True):\n",
    "        # item can be (segment, track, label)  OR  (segment, label)\n",
    "        if len(item) == 3:\n",
    "            segment, _, label = item\n",
    "        elif len(item) == 2:\n",
    "            segment, label = item\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unexpected tuple length {len(item)} from itertracks.\")\n",
    "        time_speakers.append((segment.start, segment.end, label))\n",
    "\n",
    "    time_speakers.sort(key=lambda x: x[0])\n",
    "\n",
    "    # ---- 2. Tag each Whisper word with the current speaker ----\n",
    "    idx = 0\n",
    "    for seg in segments:\n",
    "        for wd in seg[\"words\"]:\n",
    "            # advance diarization pointer until word falls into the turn\n",
    "            while idx < len(time_speakers) - 1 and wd[\"start\"] >= time_speakers[idx][1]:\n",
    "                idx += 1\n",
    "            wd[\"speaker\"] = time_speakers[idx][2]\n",
    "\n",
    "    # ---- 3. Collapse consecutive words with same speaker into turns ----\n",
    "    all_words = sorted(\n",
    "        (w for s in segments for w in s[\"words\"]),\n",
    "        key=lambda w: w[\"start\"]\n",
    "    )\n",
    "    speaker_turns = []\n",
    "    for speaker, words in groupby(all_words, key=lambda w: w[\"speaker\"]):\n",
    "        words = list(words)\n",
    "        speaker_turns.append({\n",
    "            \"speaker\": speaker,\n",
    "            \"start\":   words[0][\"start\"],\n",
    "            \"end\":     words[-1][\"end\"],\n",
    "            \"text\":    \" \".join(w[\"word\"] for w in words)\n",
    "        })\n",
    "\n",
    "    return speaker_turns\n",
    "\n",
    "# ---- call as before ----\n",
    "speaker_turns = assign_speakers(all_segments, dia_result)\n",
    "print(f\"Merged into {len(speaker_turns)} speaker turns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " • outputs/91c71ed3-5cef-4e54-a20b-ce9e5a9cc490_first2m_diarized.txt\n",
      " • outputs/91c71ed3-5cef-4e54-a20b-ce9e5a9cc490_first2m_diarized.json\n"
     ]
    }
   ],
   "source": [
    "# %% [code] 6️⃣  Serialize outputs\n",
    "def to_timestamp(sec):\n",
    "    return str(timedelta(seconds=round(sec, 3)))[:-3]\n",
    "\n",
    "txt_lines = []\n",
    "for t in speaker_turns:\n",
    "    line = f\"[{to_timestamp(t['start'])} – {to_timestamp(t['end'])}] {t['speaker']}: {t['text']}\"\n",
    "    txt_lines.append(line)\n",
    "\n",
    "txt_path  = OUTPUT_DIR / f\"{wav_path.stem}_diarized.txt\"\n",
    "json_path = OUTPUT_DIR / f\"{wav_path.stem}_diarized.json\"\n",
    "\n",
    "txt_path.write_text(\"\\n\".join(txt_lines), encoding=\"utf-8\")\n",
    "json_path.write_text(json.dumps(speaker_turns, indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" •\", txt_path)\n",
    "print(\" •\", json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate high‑level insights (topic, per‑speaker opinions, summary)\n",
    "from a diarized podcast transcript using GPT‑4o.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from textwrap import dedent\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# ── 1. Configuration ────────────────────────────────────────────────────────────\n",
    "load_dotenv()                                # loads .env if present\n",
    "OPENAI_API_KEY = \"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\"  # raises KeyError if missing\n",
    "MODEL_NAME = \"gpt-4o\"                        # alias for the latest GPT‑4o\n",
    "TRANSCRIPT_FILE = Path(\"outputs/91c71ed3-5cef-4e54-a20b-ce9e5a9cc490_first2m_diarized.json\")       # your sample file name\n",
    "TEMPERATURE = 0.3                            # keep outputs focused / deterministic\n",
    "\n",
    "# ── 2. Helper: turn JSON list → readable transcript string ──────────────────────\n",
    "def format_transcript(dialogue: list[dict]) -> str:\n",
    "    \"\"\"Convert list of {speaker,start,end,text} into a neat text block.\"\"\"\n",
    "    lines = [\n",
    "        f\"{turn['speaker']}: {turn['text'].strip()}\"\n",
    "        for turn in dialogue\n",
    "        if turn.get(\"text\")\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# ── 3. Call GPT‑4o and parse its JSON answer ────────────────────────────────────\n",
    "def generate_insights(dialogue: list[dict]) -> dict:\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "    transcript = format_transcript(dialogue)\n",
    "\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "        You are an expert conversation analyst. Analyze the following podcast\n",
    "        transcript and return **only** valid JSON (no commentary) with this schema:\n",
    "\n",
    "        {{\n",
    "          \"topic\":   string,              # one‑line topic\n",
    "          \"speaker_opinions\": {{\n",
    "              \"<speaker>\": [string, …]   # bullet‑like points per speaker\n",
    "          }},\n",
    "          \"summary\": string              # concise paragraph (≤120 words)\n",
    "        }}\n",
    "\n",
    "        Transcript:\n",
    "        ```\n",
    "        {transcript}\n",
    "        ```\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={ \"type\": \"json_object\" }\n",
    "    )\n",
    "\n",
    "    # GPT‑4o returns JSON‑formatted text – parse it safely.\n",
    "    raw = response.choices[0].message.content\n",
    "    try:\n",
    "        return json.loads(raw)\n",
    "    except json.JSONDecodeError as exc:\n",
    "        raise ValueError(\"Model did not return valid JSON\") from exc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model did not return valid JSON",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mgenerate_insights\u001b[39m\u001b[34m(dialogue)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m json.JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dev_endsem/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dev_endsem/lib/python3.12/json/decoder.py:338\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    336\u001b[39m \n\u001b[32m    337\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dev_endsem/lib/python3.12/json/decoder.py:356\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m TRANSCRIPT_FILE.open(encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      5\u001b[39m     dialogue = json.load(f)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m insights = \u001b[43mgenerate_insights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdialogue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(json.dumps(insights, indent=\u001b[32m2\u001b[39m, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mgenerate_insights\u001b[39m\u001b[34m(dialogue)\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json.loads(raw)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m json.JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mModel did not return valid JSON\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Model did not return valid JSON"
     ]
    }
   ],
   "source": [
    "if not TRANSCRIPT_FILE.exists():\n",
    "    raise SystemExit(f\"Transcript file not found: {TRANSCRIPT_FILE}\")\n",
    "\n",
    "with TRANSCRIPT_FILE.open(encoding=\"utf-8\") as f:\n",
    "    dialogue = json.load(f)\n",
    "\n",
    "insights = generate_insights(dialogue)\n",
    "\n",
    "print(json.dumps(insights, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mresponse\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_endsem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
